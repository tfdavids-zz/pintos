             +--------------------------+
             | CS 140                   |
             | PROJECT 2: USER PROGRAMS |
             | DESIGN DOCUMENT          |
             +--------------------------+

---- GROUP ----

>> Fill in the names and email addresses of your group members.

Thomas Davids <tdavids@stanford.edu>
Akshay Agrawal <akshayka@stanford.edu>
Robert Gasparyan <robertga@stanford.edu>

---- PRELIMINARIES ----

>> If you have any preliminary comments on your submission, notes for the
>> TAs, or extra credit, please give them here.

>> Please cite any offline or online sources you consulted while
>> preparing your submission, other than the Pintos documentation, course
>> text, lecture notes, and course staff.

               ARGUMENT PASSING
               ================

---- DATA STRUCTURES ----

>> A1: Copy here the declaration of each new or changed `struct' or
>> `struct' member, global or static variable, `typedef', or
>> enumeration.  Identify the purpose of each in 25 words or less.

We used no new data structures for argument passing.

---- ALGORITHMS ----

>> A2: Briefly describe how you implemented argument parsing.  How do
>> you arrange for the elements of argv[] to be in the right order?
>> How do you avoid overflowing the stack page?

Argument passing was implemented by passing a new parameter, void *aux, to the
function load(), which loads a new process in memory. The first input to
load(), const char *cmdline, is the name of the function being called (without
arguments), and the last input, void *aux, is the full name, including
arguments. This string is parsed in the function setup_args(), which decrements
the stack pointer as much as necessary to set up the stack properly. We ensure
that the elements of argv[] are in the right order by initializing argv[] at
the proper location on the stack, and then reading the addresses of the
arguments, which are already on the stack, to populate argv[]. We avoid
overflowing the stack page by limiting the length of the args[] array to one
page.

---- RATIONALE ----

>> A3: Why does Pintos implement strtok_r() but not strtok()?

/* TODO -- More detail? We might need to say _how_ strtok's output
could be corrupted. Otherwise this question seems too simple. */

strtok_r() is the reentrant version of strtok() -- that is to say, it is
thread-safe. If a timer interrupt occurred while we were parsing the
arguments, strtok()'s output could be corrupted; however, strtok_r()
will still return the correct output.

>> A4: In Pintos, the kernel separates commands into a executable name
>> and arguments.  In Unix-like systems, the shell does this
>> separation.  Identify at least two advantages of the Unix approach.

One advantage of the Unix approach is that we could potentially save space by
parsing the arguments in the shell. In the Pintos approach, we need to pass two
strings to load(): the command, and the string that was typed into the shell.
If there are a lot of spaces in between arguments, for example, we'll need to
store a larger string in memory. In the Unix approach, we can keep a smaller
amount of data around by removing these spaces and not needing to include the
command twice.

The Unix approach also has the advantage that it knows earlier which command is
actually called. In the Pintos approach, we just take the command as a raw
string all the way back to the kernel, which could cause problems if it has an
incorrect number of arguments, for example. However, if we were to follow the
Unix approach and parse the command and arguments in the shell, we could check
earlier for a possible error in the command, or for something more sinister
such as a security attack.

                 SYSTEM CALLS
                 ============

---- DATA STRUCTURES ----

>> B1: Copy here the declaration of each new or changed `struct' or
>> `struct' member, global or static variable, `typedef', or
>> enumeration.  Identify the purpose of each in 25 words or less.

Global variables in syscall.c:

/* A table mapping syscall numbers to the number of arguments a
   system call takes. Tells us the number of arguments
   to extract from the stack. */
static uint8_t syscall_arg_num[] =
  {0, 1, 1, 1, 2, 1, 1, 1, 3, 3, 2, 1, 1, 2, 1, 1, 1, 2, 1, 1};

/* A coarse lock for accessing the (thread-unsafe) filesystem. */
struct lock filesys_lock;

Members added to struct thread in thread.c:

    /* State for managing file descriptors. */
    struct file **fd_table;     /* A table of this process' file descriptors. */
    size_t fd_table_size;       /* The size of the table. */
    size_t fd_table_tail_idx;   /* The highest used fd in the table. */

New struct in thread.h:

/* A structure to keep track of a thread's child processes, which helps us
 * manage waiting on children. Keeping this around allows us to let child
 * threads die, even if we haven't waited on them yet.
 */
struct child_state
  {
    struct list_elem elem;              /* List element. */
    int exit_status;                    /* Exit status (if applicable) */
    tid_t tid;                          /* tid of child. */
    bool load_success;                  /* True if child loaded successfully*/
    struct semaphore sema;              /* For synch between parent/child */
  };

>> B2: Describe how file descriptors are associated with open files.
>> Are file descriptors unique within the entire OS or just within a
>> single process?

Each user process possesses a unique, private file descriptor table that
maps file descriptor numbers to pointers to open struct files. The table
is implemented as a linear array -- the mapping follows by having file
descriptors function as indices into the array. So the file associated
with file descriptor, say, 5, is stored in index 5 of the array. As such,
file descriptors are relative to a single process and are _not_ unique within
the entire OS.

More concretely, each user process' file descriptor table is encapsulated
by three variables stored within its thread struct: fd_table,
an array of struct file pointers; fd_table_size, the length of the array;
and fd_table_tail_idx, the highest used file descriptor. When a user
wishes to open a file, the kernel, after opening the file, checks whether
fd_table_tail_idx + 1 is within the bounds of the table. If it is, it simply
associates that file descriptor with the file and updates fd_table_tail_idx
accordingly. Otherwise, it combs through the table and associates the lowest
unused file descriptor with the new open file. If no such unused
file descriptor is found, then, as a last resort, the kernel expands the table
by a constant factor and then associates fd_table_tail_idx + 1 with the newly
opened file, updating the tail accordingly.

File descriptors corresponding to STDIN_FILENO and STDOUT_FILENO are never
assigned to files opened by the user.

---- ALGORITHMS ----

>> B3: Describe your code for reading and writing user data from the
>> kernel.

We took the first of the two approaches proposed in the project
description when implementing user memory access. In particular, we defined
the following three functions:

static bool is_valid_ptr (const void *ptr);
static bool is_valid_range (const void *ptr, size_t len);
static bool is_valid_string (const char *ptr);

is_valid_ptr takes as input a user memory address and returns true
if and only if a) the address is not NULL, b) the address is a user
address, and c) the address is mapped.

is_valid_range takes as input a contiguous block of user addresses
and returns true if and only if each address passes is_valid_ptr.

is_valid_string takes the a pointer to a string and returns true
if and only if each address passes is_valid_ptr, stopping when
either a) the NULL-terminating character is found or b) an invalid memory
access occurs, whichever happens first.

Any time we must read user memory, we first validate that it is valid,
using whichever of the three above functions is appropriate. Similarly,
before writing to user memory, we validate it using the appropriate function.
If a validation fails, we force the thread to terminate.

>> B4: Suppose a system call causes a full page (4,096 bytes) of data
>> to be copied from user space into the kernel.  What is the least
>> and the greatest possible number of inspections of the page table
>> (e.g. calls to pagedir_get_page()) that might result?  What about
>> for a system call that only copies 2 bytes of data?  Is there room
>> for improvement in these numbers, and how much?

Each invocation of is_valid_ptr calls pagedir_get_page once.

Thus, for 4096 byes of input data, the least number of invocations that would
result would be 1 -- this would happen in the case that the first memory
address failed is_valid_ptr. In the worst case, pagedir_get_page would be
called 4,096 times -- this would happen when every memory address in the
range (except possibly the last one) passed when supplied to is_valid_ptr.

If a system call only copied 2 bytes of data, then, by similar reasoning,
the least number of invocations would be 1 and the largest number of
invocations would be 2.

There is certainly room for improvement. In the first case, assuming that the
4,096 bytes constitute a single contiguous page (i.e., do not cross page
boundaries), we would in theory only need one invocation of pagedir_get_page
-- if any one of the addresses in the page is mapped, then all of them must be
mapped. The same is not necessarily true for the 2 byte case, at least if we
assume that these two bytes might straddle two pages -- if that were the case,
then we might be forced to check each byte with pagedir_get_page.

>> B5: Briefly describe your implementation of the "wait" system call
>> and how it interacts with process termination.

/* TODO -- Clean this up */

Every parent process has a list of child_states (list children) each
corresponding to a child process that has not been waited on. Child state
contains the tid, exit_status, load_success (initalized to false) and a
semaphore (initialized to 0) for synchronization between parent and child
processes. When a child thread terminates we lookup its child_state in
parents children list(if parent is still alive) and set the exit_status
appropriately. When a parent calls wait on a tid, we lookup the
child_state, remove it from the list of children and return
exit_statues. If wait is called again with the same tid we won't find the
child_state in the list and return -1.

>> B6: Any access to user program memory at a user-specified address
>> can fail due to a bad pointer value.  Such accesses must cause the
>> process to be terminated.  System calls are fraught with such
>> accesses, e.g. a "write" system call requires reading the system
>> call number from the user stack, then each of the call's three
>> arguments, then an arbitrary amount of user memory, and any of
>> these can fail at any point.  This poses a design and
>> error-handling problem: how do you best avoid obscuring the primary
>> function of code in a morass of error-handling?  Furthermore, when
>> an error is detected, how do you ensure that all temporarily
>> allocated resources (locks, buffers, etc.) are freed?  In a few
>> paragraphs, describe the strategy or strategies you adopted for
>> managing these issues.  Give an example.

Upon an error, the only resource that might need to be freed is
the global coarse filesystem lock (struct lock filesys_lock); we
allocate no memory in any of our system calls.

Whenever a user memory access fails due to a bad pointer value,
we realized that one of but two actions must take place: either

a) the return value, exit code must be set to -1 and the child must exit, or
b) the filesystem lock must be released and a) must occur as well.

Thus, we define two concise functions to handle these two cases:

static inline void exit_on (struct intr_frame *f, bool condition);
static inline void exit_on_file (struct intr_frame *f, bool condition);

where exit_on performs actions a), and exit_on_file performs actions b),
if and only if the supplied condition is true. These two functions allow
error handling to actually add to the expressiveness to our code, rather
than obscure it. For example, consider the read system call (sys_read).
We begin the function with the following two lines:

  exit_on (f, fd == STDOUT_FILENO);
  exit_on (f, !is_valid_range (buffer, length));

These exit_on calls document the preconditions for this function and
neatly handle user errors that might break this function -- they
effectively serve as ASSERTS.

Similarly, consider the following, also within read:

      lock_acquire (&filesys_lock);
      struct file *file = fd_table_get_file (fd);
      exit_on_file (f, file == NULL);

Again, the same advantages from above carry over. Since exit_on_file
releases the lock for us, we need not worry about adding messy and
redundant error handling here to do so for us.
code here

---- SYNCHRONIZATION ----

>> B7: The "exec" system call returns -1 if loading the new executable
>> fails, so it cannot return before the new executable has completed
>> loading.  How does your code ensure this?  How is the load
>> success/failure status passed back to the thread that calls "exec"?

TODO: we wait on a semaphore held by the parent that the child ups when it finishes

>> B8: Consider parent process P with child process C.  How do you
>> ensure proper synchronization and avoid race conditions when P
>> calls wait(C) before C exits?  After C exits?  How do you ensure
>> that all resources are freed in each case?  How about when P
>> terminates without waiting, before C exits?  After C exits?  Are
>> there any special cases?

TODO: talk about child_state struct

---- RATIONALE ----

>> B9: Why did you choose to implement access to user memory from the
>> kernel in the way that you did?

We used is_user_vaddr and pagedir_get_page to check if a given ptr points
to user memory or not before dereferencing it. We also created wrapper
functions is_valid_range  and is_valid_string to help us validate file
names and buffer passed to system calls. The reason we chose this approach
to implement user memory access instead of handling it in page_fault is
because it seemed simpler.

In particular, our approach allowed our code to remain expressive (see B6)
and did not incur the extra complexity required when delegating the
error handling to page faults. Our approach, however, does it entail
a performance overhead. We must validate each address before dereferencing
it -- considering that each address is likely valid, much of this work is
probably wasted. We could have also reduced redundant check (e.g. checking
multiple addresses that belong to a single page) by performing some
arithmetic to calculate whether a given address rage spanned more than one
page. But, given that we are not necessarily building a high performance
via Pintos, we chose to prefer simplicity and a slight performance hit to
complexity and a slight performance gain.

>> B10: What advantages or disadvantages can you see to your design
>> for file descriptors?

Advantages:
Since our file descriptor table is backed by an array, indexing into
it and retrieving files -- to read, write, or close -- takes constant
time. This is significantly faster than an alternative design we considered,
in which we would have backed the table with a list of structs that encapsulated
a file descriptor and its corresponding file -- retrieving files from such
a table would take time linear in the number of open files.

Additionally, backing the table by an array makes the code feel more
expressive -- file descriptors are actually indices into the file descriptor
table, fitting their definition.

Our table also does not impose a maximum limit on the number of open
file descriptors -- as such, our system is more flexible than one
that would impose such a limit. And, by dynamically allocating the table,
we save space (which comes at a premium) in our struct thread.

Finally, by separating the file descriptor code into a header file
and an implementation -- i.e., by defining an interface to the file descriptor
-- we make the implementation of the system calls clean and make our
system flexible to changes to the implementation of the table.

Disadvantages:
In the worst case, an attempt to open a file using our design will take
linear time -- we might fail to find an unused file descriptor, and
might even have to expand our table to make space for one. The amortized
time for opening a file, however, should in most cases be less than linear
_assuming_ that the user opened and closed file descriptors sequentially.
If the user program erratically opened and closed file descriptors, our
design would suffer from fragmentation and the amortized time for open
would be more costly.

However, we reasoned that opens occur less frequently than reads and writes.
So this disadvantage is mitigated by the fact that our design is optimized
for reads and writes (and closes). We also suspected that users likely do
not erratically open and close file descriptors, but we have no evidence
to back this hunch.

By not limiting the number of file descriptors, we are forced to dynamically
allocate memory for our table -- dynamic allocation is costly and increases
system complexity.

>> B11: The default tid_t to pid_t mapping is the identity mapping.
>> If you changed it, what advantages are there to your approach?

We did not change it. One advantage of changing one-to-one mapping would
be the ability to have multiple threads per process.



               SURVEY QUESTIONS
               ================

Answering these questions is optional, but it will help us improve the
course in future quarters.  Feel free to tell us anything you
want--these questions are just to spur your thoughts.  You may also
choose to respond anonymously in the course evaluations at the end of
the quarter.

>> In your opinion, was this assignment, or any one of the three problems
>> in it, too easy or too hard?  Did it take too long or too little time?

Just right!

>> Did you find that working on a particular part of the assignment gave
>> you greater insight into some aspect of OS design?

The file descriptor table and the wait / exec system calls.

>> Is there some particular fact or hint we should give students in
>> future quarters to help them solve the problems?  Conversely, did you
>> find any of our guidance to be misleading?

Nope!

>> Do you have any suggestions for the TAs to more effectively assist
>> students, either for future quarters or the remaining projects?

Nope!

>> Any other comments?

Nope!
