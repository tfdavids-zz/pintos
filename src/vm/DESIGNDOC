        +---------------------------+
		    | CS 140                    |
		    | PROJECT 3: VIRTUAL MEMORY	|
		    |	DESIGN DOCUMENT           |
		    +---------------------------+

---- GROUP ----

>> Fill in the names and email addresses of your group members.

Thomas Davids <tdavids@stanford.edu>
Akshay Agrawal <akshayka@stanford.edu>
Robert Gasparyan <robertga@stanford.edu>

---- PRELIMINARIES ----

>> If you have any preliminary comments on your submission, notes for the
>> TAs, or extra credit, please give them here.

>> Please cite any offline or online sources you consulted while
>> preparing your submission, other than the Pintos documentation, course
>> text, lecture notes, and course staff.

			PAGE TABLE MANAGEMENT
			=====================

---- DATA STRUCTURES ----

>> A1: Copy here the declaration of each new or changed `struct' or
>> `struct' member, global or static variable, `typedef', or
>> enumeration.  Identify the purpose of each in 25 words or less.

** page.h **
/* Locations that a given page may reside in. */
enum data_loc
  {
    MEMORY, /* In memory. */
    DISK,   /* In a file. */
    SWAP,   /* In swap. */
    ZEROES, /* Unitialized data (e.g. BSS) */
  };

/* Each process has a supplementary page table containing auxiliary information
   about its pages, useful for eviction and fetching pages' data. */
struct supp_pt
  {
    struct hash h;                  /* The hash table. */
    struct lock lock;               /* For synchronizing access to the table. */
    size_t num_updating;            /* The number of threads currently updating
                                       entries within the table. */
    struct condition done_updating; /* The table can only be destroyed when
                                       no threads are updating its entries. */
  };


/* Each entry within the supplementary page table is a struct supp_pte.
   Entries are keyed by the user page and describe where the page's data is. */
struct supp_pte
  {
    void *upage;            /* The user virtual address, rounded down to
                               the nearest page. */
    bool writable;          /* True if and only if the user has write access to
                               the page. */
    enum data_loc loc;      /* Where the page resides in our system. */
    size_t swap_slot_index; /* If loc == SWAP, the index into the swap table
                               that corresponds to where this upage's data is
                               stored on swap. */
    struct file *file;      /* The file from which the data was loaded, if any.
                             */
    off_t start;            /* The offset in the file at which the data begin.
                             */
    size_t bytes;           /* The number of bytes in the file spanned by the
                               data. */
    mapid_t mapping;        /* Negative if this page was not mmaped; otherwise,
                               the ID of the mapping. IDs are unique per
                               per process. */
    bool pinned;            /* True if the frame corresponding to
                               this entry should not be evicted. */
    bool being_evicted;     /* True if and only if the corresponding frame is
                               being evicted. */
    struct condition done_evicting; /* To syncrhonize with eviction. */
    struct lock l;                  /* To synchronize with eviction. */
    struct hash_elem hash_elem; /* To hook the entry into the supp_pte. */
  };

** frame.c **
/* List of all frames currently in the system; used for eviction. */
static struct list ftable;

/* To synchronize access to the ftable */
static struct lock ftable_lock;

/* A struct frame represents a (upage, kpage, thread); thread's
   page table contains a mapping between upage and kpage and is alive. */
struct frame
  {
    void *kpage;           /* A kernel virtual page. */
    void *upage;           /* The user virtual page aliased to kpage. */
    struct list_elem elem; /* The list_elem to hook the frame into the
                              frame table. */
    struct thread *t;      /* The thread to which the (upage, kpage) pair
                              belongs. */
  };

---- ALGORITHMS ----

>> A2: In a few paragraphs, describe your code for locating the frame,
>> if any, that contains the data of a given page.

When a user process page_faults on a given page we take the following
steps to locate the frame that contains it's data

 - Look up the user virtual address in supplementary page table.

 - Use frame_alloc to allocate a new frame for the page
   (A4) describes how frame_alloc works in more detail

 - Checks the loc field in the supplementary page table entry to find
   where the date of the given page resides(SWAP or DISK) and reads it
   into the allocated frame

 - It than adds the mapping from user virtual address to kernel virtual
   address of the page by calling pagedir_set_page

>> A3: How does your code coordinate accessed and dirty bits between
>> kernel and user virtual addresses that alias a single frame, or
>> alternatively how do you avoid the issue?

We avoid this issue by having kernel always using the user virtual address
when accessing user memory. This happens in system calls where we first
validate that all that addresses passed in by the user are valid user
memory (<PHYS_BASE) but than use the same addresses to access the
user data.


---- SYNCHRONIZATION ----

>> A4: When two user processes both need a new frame at the same time,
>> how are races avoided?

When a process allocates a frame it first calls palloc_get_page and than
adds an entry to the frame table. If palloc_get_page returns null, we must
evict another frame and return its page. 

Both adding and evicting frames from the frame_table are synchronized by
the global ftable_lock, and palloc_get_page has internal synchronization. 

---- RATIONALE ----

>> A5: Why did you choose the data structure(s) that you did for
>> representing virtual-to-physical mappings?

Supplementary page table:
  We chose to back the supplementary page table with a hash table primarily
because we reasoned that our code would have to look-up many supplementary
page table entries, and we knew that a hash table would provide a
(theoretically) constant time lookup. In particular, we need to look-up
supplementary page table entries when we validate user pointers, handle
page faults, examine frames in second chance, free mapped user pages,
and so on.

An alternative to a hash table might have been a list, which would have
supported faster insertion and deletion (so allocation and freeing could
have been faster). However, we reasoned that insertions and deletions are
likely much less frequent than lookups, and the O(n) lookups that a list
would incur would slow our system down tremendously.

An array would have been intractable because we would have needed an entry
for every virtual address.

Frame table:
  We choose to back the frame table with a list because we reasoned that
the vast majority of accesses would be sequential, not random. That is, the
primary use case for the table is eviction, and the second chance algorithm
simply iterates through the list, popping the head and pushing it to the back.
Since we have to iterate through the list for eviction, we could do no better
than O(n). Additionally, using a list makes insertions and deletions into the
table constant time (i.e. frame frees and frame unallocs become faster).

  We did consider using a hash table for the frame table, instead of a list.
A hash table would be beneficial because look-ups would be faster -- when
unmapping a file or freeing a thread's frames, we could quickly find its frames.
However, deletion and insertion into the table would be more costly. The number
deletions from the table is roughly equal to the number of look-ups we do. Thus,
we reasoned that a list might perform on par (or better with) a table, and would
avoid the latter's memory overhead, to boot.

As before, an array would have been intractable.

		       PAGING TO AND FROM DISK
		       =======================

---- DATA STRUCTURES ----

>> B1: Copy here the declaration of each new or changed `struct' or
>> `struct' member, global or static variable, `typedef', or
>> enumeration.  Identify the purpose of each in 25 words or less.

/* Swap device provides internally synchronized interface with
   swap partition of the disk */
static struct block *swap_device;

/* A bitmap, where every bit corresponds to a slot in a swap
   partition, if bit i is on => page at index i is free in swap */
static struct bitmap *swap_slots;

/* Synchronizes access to the ftable */
static struct lock swap_slots_lock;

/* Block interface writes one sector at a time;
   sector_per_page is the number of sectors in a page. */
static size_t sectors_per_page = PGSIZE / BLOCK_SECTOR_SeIZE;

/* Number of pages that can fit in swap. */
size_t num_swap_slots;

---- ALGORITHMS ----

>> B2: When a frame is required but none is free, some frame must be
>> evicted.  Describe your code for choosing a frame to evict.

We implemented second chance algorithm for choosing which frame to evict.
Since our frame table is a list instead of keeping an arrow we just
rotate elements in the list so that we always start checking at the
first entry of the list
 
      if entry was accessed
        set accessed to false and move frame to the back of the list
      else
        pop frame from list 
        if non-writable file
          just overwrite
        else if mmaping 
          if dirty bit set          
            write to disk
        else 
          write to swap
      push element to the back of he list(now it belongs to the new process)

>> B3: When a process P obtains a frame that was previously used by a
>> process Q, how do you adjust the page table (and any other data
>> structures) to reflect the frame Q no longer has?

Process Q can be accessed via a pointer in every frame it owns so when P
obtains Q's frame, we first set the present bit to false in the pagedir
of Q and then modify the entry in the supplamantry page table to specify
where the content of that page resides(DISK or SWAP).
So when process Q tries to access that page it will pagefault(pagedir is
set to not present) and check the supplementary page table for loading the
page back.

>> B4: Explain your heuristic for deciding whether a page fault for an
>> invalid virtual address should cause the stack to be extended into
>> the page that faulted.

When a page fault occurs on a page that doesn't have a supplementary page
table entry we check to see if this is caused by the stack growing. We
add a supplementary page table entry if the address is above esp - 32
(because PUSHA could access memory that's 32 below esp) and we also check
if it is above STACK_LIMIT, if not we consider this an invalid memory
access and exit the process.

STACK_LIMIT is picked to be 8MB below PHYS_BASE.



---- SYNCHRONIZATION ----

>> B5: Explain the basics of your VM synchronization design.  In
>> particular, explain how it prevents deadlock.  (Refer to the
>> textbook for an explanation of the necessary conditions for
>> deadlock.)

Access to swap is synchronized by a single global lock that synchronizes
access to swap_slots so that two users never get the same swap_index.
Read and Writes into swap_device are synchronized internally.

We use an individual lock to synchronize access to every entry in the
supplementary page table. Entries are modified by the process they belong
to when it page_faults and also the process that evicts a frame owned by
that process. Using individual locks enables a process to page_fault on a
different page without blocking while one of it's other pages is being
evicted.

We also have a lock for the whole supplementary page table, this is used
to prevent a race condition where a process Q is in the middle of evicting
process P's frame when P exits and deletes it's supp_tb, so when Q is done
with eviction and wants to update the P's supp_tb it is gone ! We prevent
this from happening by blocking the exit process while num_updating > 0.
Num_updating of a process is the number of other processes that are
currently in the middle of evicting one of it's frames.


We have the first three conditions for deadlock but prevent the fourth one:


1. Mutual exclusion - we have this because we use locks

2. Hold and wait - we have this, for example we acquire supplementary page
                   table entry lock while we are holding the frame table
                   lock
3. No preemption - we have this because locks can be released only
                   voluntarily by a process                   
4. Circular Wait - we prevent this by making sure that we acquire the
                   locks in the same order everywhere.

Also we release all the locks when a process is exiting.

1. Before starting the eviction process P sets the present bit in pagedir
of Q to false, which would cause Q to pagefault if it tried to access or
modify the page.

2. P also sets the being_evicted bit to true in Q's page table entry to
true before it start the eviction process. Process P will wait on that
being_evicted == true until Q finishes the eviction process, resets the
bit and signals process P to continue.

>> B7: Suppose a page fault in process P causes a page to be read from
>> the file system or swap.  How do you ensure that a second process Q
>> cannot interfere by e.g. attempting to evict the frame while it is
>> still being read in?

Before allocating a frame or starting to read the page process P will
first set pinned=true in the corresponding supplementary page table entry
and only unpin it when it's done loading the page into memory. And the
eviction algorithm passes on frames that are pinned (this is checked by
checking bool pinned in the corresponding supplementary page table entry).
This prevents from a frame being evicted while it's still being read
into.

>> B8: Explain how you handle access to paged-out pages that occur
>> during system calls.  Do you use page faults to bring in pages (as
>> in user programs), or do you have a mechanism for "locking" frames
>> into physical memory, or do you use some other design?  How do you
>> gracefully handle attempted accesses to invalid virtual addresses?

1. We first pin and load all the pages for all the parameters passed into
system calls but we don't unpin them after we are done loading, instead we
keep them pinned until we are done with the system call and unpin them
than. Keeping these frames pinned the entire time prevents them from being
evicted so the kernel never page-faults.

2. When a user process tries to access an invalid virtual address we
terminate the process with exit_status = -1 and free all the resources
that belonged to it including frames and swap_slots.

---- RATIONALE ----

>> B9: A single lock for the whole VM system would make
>> synchronization easy, but limit parallelism.  On the other hand,
>> using many locks complicates synchronization and raises the
>> possibility for deadlock but allows for high parallelism.  Explain
>> where your design falls along this continuum and why you chose to
>> design it this way.

Our design uses many locks and provides great parallelism. We successfully
avoided any deadlock situations by making sure we acquire locks in the
same order and only hold on to them when necessary. But having high
parallelism did create some race conditions that we spent many hours
debugging. Many of them were a result of parallelizing frame_evict where we
we separated the code for evicting a frame and code for writing he content
of the evicted frame to disk/swap into two separate critical regions so
that access to the frame table is not blocked by a slow I/O
instruction. But his created a race condition between a process exiting
and its frames being evicted (ex in B5). We were able to prevent this race
conditions by using conditional variables which may have complicated the
design a little bit but we achieved great performance by parallelizing as
many functions as possible. We even implemented read-write locks for the
access to the supplementary page table because we assumed most of the
access would be read-only but overhead created by the read-write locks was
too much. 

			 MEMORY MAPPED FILES
			 ===================

---- DATA STRUCTURES ----

>> C1: Copy here the declaration of each new or changed `struct' or
>> `struct' member, global or static variable, `typedef', or
>> enumeration.  Identify the purpose of each in 25 words or less.

---- ALGORITHMS ----

>> C2: Describe how memory mapped files integrate into your virtual
>> memory subsystem.  Explain how the page fault and eviction
>> processes differ between swap pages and other pages.

Our system needed to keep track of each process' memory mapped files.
In particular, we needed to keep track of 1) which pages were mapped,
2) from which files and 3) from what location in those files were those
pages mapped, and 4) which pages belonged to what mappings.

We decided to fold this tracking information into the supplementary
page table entry -- the entry already needed to keep track of the
file (if any) a page was sourced from and the offset into that file,
along with the number of bytes read from that file ( 2) and 3) above).
By simply adding a mapid_t to each supp_pte, our system is able to track
1) and 4) as well -- if the ID is negative, then the page is not mapped;
otherwise, it is mapped if its ID appears to be valid.

In particular, a file memory mapped at user virtual address "vaddr" receives
a mapid_t equal to (mapid_t) vaddr. Since no two mappings within the same
virtual address space can span overlapping user virtual addresses, the starting
address of the mapping uniquely identifies it. Moreover, since a process
already knows the address of its memory mapped file, we are not revealing
any sensitive information by choosing this naming policy.

Memory mapped files are lazy-loaded -- when mmap-d, we create the necessary
supplementary page table entries but do not fetch the actual data until
we fault upon their corresponding pages.

The page fault and eviction policies differ slightly between swap pages
and other pages. The basic page fault mechanism is the same for both --
if the faulted address was legal, then load the page's frame and data
and update its supplementary page table and page table. When evicting
frames, if a page is read-only, then we do not store it in swap -- rather,
we remember to simply fetch it from the file from which we read it in
when we next fault on the page. If a page is a part of a memory mapped file,
we also use its file as its backing store -- only if the page is dirty
do we write its data back to the file. Regardless of whether it is dirty,
we remember to fetch it from its file. Finally, if a page does not fit
either of those categories, then we store it in swap and remember where we
stored it so we can retrieve it when we fault upon it.

Upon exiting, we write the contents of memory mapped pages if they are dirty.

>> C3: Explain how you determine whether a new file mapping overlaps
>> any existing segment.

For each file that we are asked to map, we first compute the number of
pages we will need in order to map the entire file. If the address
plus the number of pages times the page size extends into the stack region
(demarcated by STACK_LIMIT in vaddr.h), then we do not map the file. Next,
for each page that the memory mapped file would need, we check whether there
already exists an entry for that page in our supplementary page table. If so,
then the new file mapping would overlap an existing segment, and we do not
create the mapping.

---- RATIONALE ----

>> C4: Mappings created with "mmap" have similar semantics to those of
>> data demand-paged from executables, except that "mmap" mappings are
>> written back to their original files, not to swap.  This implies
>> that much of their implementation can be shared.  Explain why your
>> implementation either does or does not share much of the code for
>> the two situations.

Our implementation shares much of the code in the two situations. Indeed,
both types of data are tracked using the same structures (struct frame's
and struct supp_pte's). The code for eviction and fetching for both types
of data is almost identical -- we simply check whether we should write
data back to a file or to swap. Mappings have a bit of extra code upon
process exit, since they must be written back to the file if they are dirty.
But, again, the code is shared.

We decided to share the code in order to minimize code duplication and to
promote clarity -- the code would become confusing if we different code
for two very similar situations.

			   SURVEY QUESTIONS
			   ================

Answering these questions is optional, but it will help us improve the
course in future quarters.  Feel free to tell us anything you
want--these questions are just to spur your thoughts.  You may also
choose to respond anonymously in the course evaluations at the end of
the quarter.

>> In your opinion, was this assignment, or any one of the three problems
>> in it, too easy or too hard?  Did it take too long or too little time?

>> Did you find that working on a particular part of the assignment gave
>> you greater insight into some aspect of OS design?

>> Is there some particular fact or hint we should give students in
>> future quarters to help them solve the problems?  Conversely, did you
>> find any of our guidance to be misleading?

>> Do you have any suggestions for the TAs to more effectively assist
>> students, either for future quarters or the remaining projects?

>> Any other comments?
